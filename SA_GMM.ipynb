{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8872dd8c-3244-4707-b2d6-96d6e7ad52b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "@Author - Păpăluță Vasile - vpapaluta06@gmail.com\n",
    "'''\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "class GMM:\n",
    "    '''\n",
    "        This class is the implementation of the Gaussian Mixture Models \n",
    "        inspired by sci-kit learn implementation.\n",
    "    '''\n",
    "    def __init__(self, n_components, max_iter = 100, comp_names=None):\n",
    "        '''\n",
    "            This functions initializes the model by seting the following paramenters:\n",
    "                :param n_components: int\n",
    "                    The number of clusters in which the algorithm must split\n",
    "                    the data set\n",
    "                :param max_iter: int, default = 100\n",
    "                    The number of iteration that the algorithm will go throw to find the clusters\n",
    "                :param comp_names: list of strings, default=None\n",
    "                    In case it is setted as a list of string it will use to\n",
    "                    name the clusters\n",
    "        '''\n",
    "        self.n_componets = n_components\n",
    "        self.max_iter = max_iter\n",
    "        if comp_names == None:\n",
    "            self.comp_names = [f\"comp{index}\" for index in range(self.n_componets)]\n",
    "        else:\n",
    "            self.comp_names = comp_names\n",
    "        # pi list contains the fraction of the dataset for every cluster\n",
    "        self.pi = [1/self.n_componets for comp in range(self.n_componets)]\n",
    "\n",
    "    def multivariate_normal(self, X, mean_vector, covariance_matrix):\n",
    "        '''\n",
    "            This function implements the multivariat normal derivation formula,\n",
    "            the normal distribution for vectors it requires the following parameters\n",
    "                :param X: 1-d numpy array\n",
    "                    The row-vector for which we want to calculate the distribution\n",
    "                :param mean_vector: 1-d numpy array\n",
    "                    The row-vector that contains the means for each column\n",
    "                :param covariance_matrix: 2-d numpy array (matrix)\n",
    "                    The 2-d matrix that contain the covariances for the features\n",
    "        '''\n",
    "        return (2*np.pi)**(-len(X)/2)*np.linalg.det(covariance_matrix)**(-1/2)*np.exp(-np.dot(np.dot((X-mean_vector).T, np.linalg.inv(covariance_matrix)), (X-mean_vector))/2)\n",
    "\n",
    "    def fit(self, X):\n",
    "        '''\n",
    "            The function for training the model\n",
    "                :param X: 2-d numpy array\n",
    "                    The data must be passed to the algorithm as 2-d array, \n",
    "                    where columns are the features and the rows are the samples\n",
    "        '''\n",
    "        # Spliting the data in n_componets sub-sets\n",
    "        new_X = np.array_split(X, self.n_componets)\n",
    "        # Initial computation of the mean-vector and covarience matrix\n",
    "        self.mean_vector = [np.mean(x, axis=0) for x in new_X]\n",
    "        self.covariance_matrixes = [np.cov(x.T) for x in new_X]\n",
    "        # Deleting the new_X matrix because we will not need it anymore\n",
    "        del new_X\n",
    "        for iteration in range(self.max_iter):\n",
    "            ''' --------------------------   E - STEP   -------------------------- '''\n",
    "            # Initiating the r matrix, evrey row contains the probabilities\n",
    "            # for every cluster for this row\n",
    "            self.r = np.zeros((len(X), self.n_componets))\n",
    "            # Calculating the r matrix\n",
    "            for n in range(len(X)):\n",
    "                for k in range(self.n_componets):\n",
    "                    self.r[n][k] = self.pi[k] * self.multivariate_normal(X[n], self.mean_vector[k], self.covariance_matrixes[k])\n",
    "                    self.r[n][k] /= sum([self.pi[j]*self.multivariate_normal(X[n], self.mean_vector[j], self.covariance_matrixes[j]) for j in range(self.n_componets)])\n",
    "            # Calculating the N\n",
    "            N = np.sum(self.r, axis=0)\n",
    "            ''' --------------------------   M - STEP   -------------------------- '''\n",
    "            # Initializing the mean vector as a zero vector\n",
    "            self.mean_vector = np.zeros((self.n_componets, len(X[0])))\n",
    "            # Updating the mean vector\n",
    "            for k in range(self.n_componets):\n",
    "                for n in range(len(X)):\n",
    "                    self.mean_vector[k] += self.r[n][k] * X[n]\n",
    "            self.mean_vector = [1/N[k]*self.mean_vector[k] for k in range(self.n_componets)]\n",
    "            # Initiating the list of the covariance matrixes\n",
    "            self.covariance_matrixes = [np.zeros((len(X[0]), len(X[0]))) for k in range(self.n_componets)]\n",
    "            # Updating the covariance matrices\n",
    "            for k in range(self.n_componets):\n",
    "                self.covariance_matrixes[k] = np.cov(X.T, aweights=(self.r[:, k]), ddof=0)\n",
    "            self.covariance_matrixes = [1/N[k]*self.covariance_matrixes[k] for k in range(self.n_componets)]\n",
    "            # Updating the pi list\n",
    "            self.pi = [N[k]/len(X) for k in range(self.n_componets)]\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "            The predicting function\n",
    "                :param X: 2-d array numpy array\n",
    "                    The data on which we must predict the clusters\n",
    "        '''\n",
    "        probas = []\n",
    "        for n in range(len(X)):\n",
    "            probas.append([self.multivariate_normal(X[n], self.mean_vector[k], self.covariance_matrixes[k])\n",
    "                           for k in range(self.n_componets)])\n",
    "        cluster = []\n",
    "        for proba in probas:\n",
    "            cluster.append(self.comp_names[proba.index(max(proba))])\n",
    "        return cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ccac27-8d8b-49e4-b240-7b703b1958b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
